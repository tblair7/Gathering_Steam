{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pckl\n",
    "\n",
    "# personal script\n",
    "import tokenize_review\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjustable parameters\n",
    "num_features = 1000\n",
    "num_topics = 10\n",
    "num_top_words = 10\n",
    "num_top_reviews = 3\n",
    "\n",
    "df = pckl.load(open('SSR_sorted_data_0122.pckl','rb'))\n",
    "reviews = df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_tokenizer = WhitespaceTokenizer()\n",
    "lancaster = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "try:\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \n",
    "    # import a dictionary of English contractions from another file\n",
    "    from contractions import contractions_dict\n",
    "    contraction_dict = contractions_dict\n",
    "\n",
    "    # replace the contractions with their expanded form\n",
    "    for contraction, expansion in contraction_dict.items():\n",
    "        text = text.replace(contraction.lower(),expansion.lower())\n",
    "    \n",
    "    # get rid of newlines\n",
    "    symbols = ['\\'', '\\\"', '.', ',', '[', ']', '(', ')', '?', '!', '@', '$', '#', '&', '%']\n",
    "    \n",
    "    text = text.strip().replace('\\n', ' ').replace('\\r', ' ').replace('-',' ')\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        text = text.replace(symbol, '')\n",
    "\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tokens(review, *args):\n",
    "\n",
    "    ws_tokenized = ws_tokenizer.tokenize(review)\n",
    "    #print(type(ws_tokenized),ws_tokenized[0])\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token in ws_tokenized:\n",
    "        if token not in stopwords:\n",
    "            cleaned_tokens.append(token)\n",
    "            \n",
    "    #print(type(cleaned_tokens),cleaned_tokens[0])\n",
    "\n",
    "    stemmed_tokens = []\n",
    "\n",
    "    try:\n",
    "        method = args[0]\n",
    "    except:\n",
    "        method = 'lancaster'\n",
    "\n",
    "    if method == 'lancaster':\n",
    "        for token in cleaned_tokens:\n",
    "            #stemmed_tokens.append(lancaster.stem(token))\n",
    "            stemmed_tokens.append(lancaster.stem(token.lower().strip()))\n",
    "\n",
    "    elif method == 'porter':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(porter.stem(token.lower().strip()))\n",
    "\n",
    "    elif method == 'snowball':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(snowball.stem(token.lower().strip()))\n",
    "\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(reviews):\n",
    "    cleaned_reviews = []\n",
    "\n",
    "    for review in reviews:\n",
    "        review_tokens = []\n",
    "        cleaned_text = cleanText(review)\n",
    "        cleaned_reviews.append(gen_tokens(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             max_features=num_features,\n",
    "                             ngram_range=(1,2), \n",
    "                             max_df=0.9, min_df=3)\n",
    "\n",
    "# use NMF model with the Frobenius norm\n",
    "implement_nmf = NMF(n_components=num_topics,\n",
    "                    random_state=1,\n",
    "                    solver='mu',\n",
    "                    beta_loss='frobenius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = vectorizer.fit_transform(cleaned_reviews)\n",
    "transform_array = transform.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative matrix factorization (NMF) implementation W*H = original matrix\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n",
    "\n",
    "W = implement_nmf.fit_transform(transform_array)\n",
    "H = implement_nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_top_words = 5\n",
    "\n",
    "num_features = 1000\n",
    "num_topics = 20\n",
    "num_top_words = 5 # words per topic\n",
    "num_top_reviews = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with _vaderSentiment_ package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(vectorizer, clf, W, df, num_top_words, num_top_reviews):\n",
    "    ''' Print out topics discovered by a model '''\n",
    "    \n",
    "    # get list of feature names\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    # get vader sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()    \n",
    "    \n",
    "    # list of topics and reviews to return\n",
    "    topics, sentiments, reviews = [], [], []\n",
    "    \n",
    "    # loop over all the topics\n",
    "    for topic_id, topic in enumerate(clf.components_):\n",
    "        \n",
    "        sentiment_sum = 0\n",
    "        \n",
    "        # grab the list of words describing the topic\n",
    "        word_list = []\n",
    "        for i in topic.argsort()[:-num_top_words - 1:-1]:\n",
    "            word_list.append(feature_names[i])\n",
    "        \n",
    "        # split words in case there are some bigrams and get unique set\n",
    "        split_list = []\n",
    "        for word in word_list:\n",
    "            for split in word.split():\n",
    "                split_list.append(split)\n",
    "        topic_words = list(set(split_list))\n",
    "        \n",
    "        # append topic words as a single string\n",
    "        topics.append(' '.join([word for word in topic_words]))\n",
    "        \n",
    "        # print topic number and topic words\n",
    "        print('Topic #%02d: %s' % (topic_id+1, topics[-1]))\n",
    "\n",
    "        # loop over reviews for each topic\n",
    "        top_doc_indices = np.argsort( W[:,topic_id] )[::-1][0:num_top_reviews]\n",
    "        \n",
    "        for doc_index in top_doc_indices:\n",
    "            \n",
    "            # check that the review contains one of the topic words\n",
    "            if any(word in df['cleaned_reviews'].iloc[doc_index].lower() for word in topic_words):\n",
    "                \n",
    "                # sentiment analysis\n",
    "                vader = analyzer.polarity_scores(df['cleaned_reviews'].iloc[doc_index])\n",
    "                \n",
    "                # append current review to the list \n",
    "                reviews.append(df.iloc[doc_index].to_dict())\n",
    "                reviews[-1]['topic']       = topic_id\n",
    "                reviews[-1]['topic_words'] = ' '.join([word for word in topic_words])\n",
    "                reviews[-1]['sentiment']   = vader['compound']\n",
    "                \n",
    "                sentiment_sum += vader['compound']\n",
    "                \n",
    "                #print('User %20s on %s with rating %s' % (df['reviewerName'].iloc[doc_index][:20], \n",
    "                                     #df['reviewTime'].iloc[doc_index], df['overall'].iloc[doc_index]))            \n",
    "                print(\"VADER: %f\" % vader['compound'])\n",
    "                #print(reviews[-1]['reviewText'])\n",
    "            else:\n",
    "                print(\"WARNING: TOPIC NOT IN DOCUMENT\")\n",
    "                            \n",
    "            print()\n",
    "        \n",
    "        sentiments.append(sentiment_sum)\n",
    "        \n",
    "    return topics, sentiments, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #01: level gam puzzl mech new\n",
      "VADER: 0.927400\n",
      "\n",
      "VADER: 0.994200\n",
      "\n",
      "VADER: 0.989300\n",
      "\n",
      "VADER: 0.970500\n",
      "\n",
      "VADER: 0.968600\n",
      "\n",
      "VADER: 0.982600\n",
      "\n",
      "VADER: 0.799200\n",
      "\n",
      "VADER: 0.985600\n",
      "\n",
      "VADER: 0.938200\n",
      "\n",
      "VADER: 0.972600\n",
      "\n",
      "Topic #02: ev iv play gam\n",
      "VADER: 0.340000\n",
      "\n",
      "VADER: 0.340000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.340000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.802000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "Topic #03: rol steph saus\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: -0.381800\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.542300\n",
      "\n",
      "VADER: -0.025800\n",
      "\n",
      "VADER: 0.726900\n",
      "\n",
      "VADER: -0.296000\n",
      "\n",
      "Topic #04: play good puzzl gam\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.648600\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "Topic #05: hurt fuck brain 10\n",
      "VADER: -0.510600\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.542300\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.765000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.883400\n",
      "\n",
      "Topic #06: excel amaz puzzl gam\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: -0.077200\n",
      "\n",
      "VADER: 0.401900\n",
      "\n",
      "VADER: -0.340000\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.273200\n",
      "\n",
      "VADER: 0.840200\n",
      "\n",
      "VADER: 0.899500\n",
      "\n",
      "Topic #07: cook tru perfect saus\n",
      "VADER: 0.571900\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.757900\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.726900\n",
      "\n",
      "VADER: -0.102700\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: 0.807400\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.730000\n",
      "\n",
      "Topic #08: gam lik pric wor feel\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.557400\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.361200\n",
      "\n",
      "VADER: 0.855500\n",
      "\n",
      "VADER: 0.526700\n",
      "\n",
      "VADER: -0.128000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.807400\n",
      "\n",
      "VADER: 0.938200\n",
      "\n",
      "Topic #09: edit gre puzzl gam\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.340000\n",
      "\n",
      "VADER: 0.250000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.648600\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: 0.557400\n",
      "\n",
      "VADER: 0.750600\n",
      "\n",
      "Topic #10: fun solv puzzl mad\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.969800\n",
      "\n",
      "VADER: 0.857100\n",
      "\n",
      "VADER: 0.796400\n",
      "\n",
      "VADER: -0.604100\n",
      "\n",
      "VADER: 0.831600\n",
      "\n",
      "VADER: 0.659700\n",
      "\n",
      "VADER: -0.493900\n",
      "\n",
      "VADER: 0.250000\n",
      "\n",
      "VADER: 0.226300\n",
      "\n",
      "Topic #11: difficult gam delicy puzzl enjoy\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: 0.177900\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: -0.153100\n",
      "\n",
      "VADER: -0.709600\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: 0.077200\n",
      "\n",
      "Topic #12: soul sery dark puzzl\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.202300\n",
      "\n",
      "VADER: 0.340000\n",
      "\n",
      "VADER: -0.638100\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.526700\n",
      "\n",
      "VADER: 0.955200\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.817600\n",
      "\n",
      "VADER: -0.153100\n",
      "\n",
      "Topic #13: ev gam best puzzl mad\n",
      "VADER: 0.250000\n",
      "\n",
      "VADER: 0.636900\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.636900\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: -0.177900\n",
      "\n",
      "VADER: 0.784500\n",
      "\n",
      "VADER: 0.855500\n",
      "\n",
      "VADER: 0.765000\n",
      "\n",
      "VADER: 0.636900\n",
      "\n",
      "Topic #14: lov gam puzzl challeng nic\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.177900\n",
      "\n",
      "VADER: -0.387500\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: 0.611100\n",
      "\n",
      "VADER: 0.822500\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "Topic #15: strike 3d puzzl simpl\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.726900\n",
      "\n",
      "VADER: 0.069700\n",
      "\n",
      "VADER: 0.954300\n",
      "\n",
      "VADER: 0.984700\n",
      "\n",
      "VADER: 0.938200\n",
      "\n",
      "VADER: 0.988400\n",
      "\n",
      "Topic #16: real saus gam good control\n",
      "VADER: 0.361200\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.726900\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: -0.361200\n",
      "\n",
      "VADER: 0.976600\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.836000\n",
      "\n",
      "VADER: 0.440400\n",
      "\n",
      "VADER: 0.980500\n",
      "\n",
      "Topic #17: masterpiec design level wel\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.636900\n",
      "\n",
      "VADER: 0.493900\n",
      "\n",
      "VADER: 0.051600\n",
      "\n",
      "VADER: 0.296000\n",
      "\n",
      "VADER: -0.628300\n",
      "\n",
      "VADER: 0.802000\n",
      "\n",
      "VADER: 0.817600\n",
      "\n",
      "Topic #18: hard want puzzl hel big\n",
      "VADER: -0.102700\n",
      "\n",
      "VADER: -0.102700\n",
      "\n",
      "VADER: -0.102700\n",
      "\n",
      "VADER: 0.273200\n",
      "\n",
      "VADER: -0.102700\n",
      "\n",
      "VADER: -0.025800\n",
      "\n",
      "VADER: 0.726900\n",
      "\n",
      "VADER: -0.273200\n",
      "\n",
      "VADER: 0.340000\n",
      "\n",
      "VADER: -0.102700\n",
      "\n",
      "Topic #19: lov simpl fin near im\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: -0.750600\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.827100\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.458800\n",
      "\n",
      "VADER: 0.812600\n",
      "\n",
      "VADER: 0.946000\n",
      "\n",
      "VADER: 0.659700\n",
      "\n",
      "Topic #20: incred smart mak dumb feel\n",
      "VADER: 0.542300\n",
      "\n",
      "VADER: 0.401900\n",
      "\n",
      "VADER: 0.401900\n",
      "\n",
      "VADER: 0.226300\n",
      "\n",
      "VADER: -0.153100\n",
      "\n",
      "VADER: 0.000000\n",
      "\n",
      "VADER: 0.128000\n",
      "\n",
      "VADER: 0.921700\n",
      "\n",
      "VADER: 0.250000\n",
      "\n",
      "VADER: 0.077200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics, sentiments, assc_reviews = display_topics(vectorizer, implement_nmf, W, df, num_top_words, num_top_reviews)\n",
    "\n",
    "#(vectorizer, clf, W, df, n_top_words, n_top_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.528199999999998,\n",
       " 6.412,\n",
       " 0.24600000000000005,\n",
       " 4.6122,\n",
       " -0.1695000000000002,\n",
       " 2.8968,\n",
       " 3.9502,\n",
       " 2.8036,\n",
       " 0.6669999999999999,\n",
       " 3.4929,\n",
       " -2.7748000000000004,\n",
       " 1.6460000000000001,\n",
       " 5.9178,\n",
       " 2.2262,\n",
       " 4.6622,\n",
       " 4.4008,\n",
       " 2.4697000000000005,\n",
       " 0.5276000000000001,\n",
       " 2.9536,\n",
       " 2.7962]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(int(x) for x in sentiments)\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = sqrt of sum of abs(matrix difference), i.e., how well did the refactorization work?\n",
    "reconstruction_error = implement_nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "\n",
    "#upvote_window = np.diff(df['upvotes'], n=1)\n",
    "#zeros_upvote_window = np.zeros(window_size)\n",
    "\n",
    "#full_upvote_window = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "upvote_window = []\n",
    "percent_window = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if i >= window_size - 1:\n",
    "        upvote_period = df['upvotes'].iloc[i] - df['upvotes'].iloc[i+1-window_size]\n",
    "        upvote_window.append(upvote_period)\n",
    "        percent_window.append(upvote_period/window_size)\n",
    "    else:\n",
    "        upvote_window.append(df['upvotes'].iloc[i])\n",
    "        percent_window.append(df['upvotes'].iloc[i]/df['total_votes'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>upvoted</th>\n",
       "      <th>comment_upvotes</th>\n",
       "      <th>comment_funny_votes</th>\n",
       "      <th>early_review</th>\n",
       "      <th>time_of_review</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>playtime_2weeks</th>\n",
       "      <th>last_played</th>\n",
       "      <th>games_owned</th>\n",
       "      <th>author_reviews</th>\n",
       "      <th>purchased</th>\n",
       "      <th>free</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>percent_upvotes</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not be fooled.\\nThis game will invade your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 07:48:44</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-26 07:57:48</td>\n",
       "      <td>6501</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fool gam invad subconscy play hour burn many s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most challenging puzzle games out t...</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 08:43:07</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-18 08:48:29</td>\n",
       "      <td>361</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>on challeng puzzl gam nev unfair mech push rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You have to play the game to understand it and...</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 11:00:45</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-26 17:03:53</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>play gam understand solv puzzl real satisfy ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This game, huh? What a package! \\n\\nRight from...</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 12:27:56</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24 12:00:53</td>\n",
       "      <td>365</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gam huh pack right word go gam lov op menu mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bet you are wondering what this game is actu...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 12:38:16</td>\n",
       "      <td>4109</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-15 17:05:17</td>\n",
       "      <td>493</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bet wond gam act lik play wheth wor money revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  upvoted  \\\n",
       "0  Do not be fooled.\\nThis game will invade your ...     True   \n",
       "1  One of the most challenging puzzle games out t...     True   \n",
       "2  You have to play the game to understand it and...     True   \n",
       "3  This game, huh? What a package! \\n\\nRight from...     True   \n",
       "4  I bet you are wondering what this game is actu...     True   \n",
       "\n",
       "   comment_upvotes  comment_funny_votes  early_review      time_of_review  \\\n",
       "0               71                   41         False 2016-04-18 07:48:44   \n",
       "1               34                   20         False 2016-04-18 08:43:07   \n",
       "2               14                    0         False 2016-04-18 11:00:45   \n",
       "3               10                    2         False 2016-04-18 12:27:56   \n",
       "4               15                    6         False 2016-04-18 12:38:16   \n",
       "\n",
       "   minutes_played  playtime_2weeks         last_played  games_owned  \\\n",
       "0             330                0 2018-11-26 07:57:48         6501   \n",
       "1             245                0 2016-04-18 08:48:29          361   \n",
       "2            1445                0 2016-05-26 17:03:53           67   \n",
       "3             400                0 2017-04-24 12:00:53          365   \n",
       "4            4109                0 2017-02-15 17:05:17          493   \n",
       "\n",
       "   author_reviews  purchased   free  upvotes  total_votes  percent_upvotes  \\\n",
       "0             132      False  False        1            1              1.0   \n",
       "1              10      False  False        2            2              1.0   \n",
       "2               1       True  False        3            3              1.0   \n",
       "3              68      False  False        4            4              1.0   \n",
       "4               3      False  False        5            5              1.0   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  fool gam invad subconscy play hour burn many s...  \n",
       "1  on challeng puzzl gam nev unfair mech push rol...  \n",
       "2  play gam understand solv puzzl real satisfy ev...  \n",
       "3  gam huh pack right word go gam lov op menu mak...  \n",
       "4  bet wond gam act lik play wheth wor money revi...  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckl.dump(data,open('SSR_sorted_data_0122.pckl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>upvoted</th>\n",
       "      <th>comment_upvotes</th>\n",
       "      <th>comment_funny_votes</th>\n",
       "      <th>early_review</th>\n",
       "      <th>time_of_review</th>\n",
       "      <th>minutes_played</th>\n",
       "      <th>playtime_2weeks</th>\n",
       "      <th>last_played</th>\n",
       "      <th>games_owned</th>\n",
       "      <th>author_reviews</th>\n",
       "      <th>purchased</th>\n",
       "      <th>free</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>percent_upvotes</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not be fooled.\\nThis game will invade your ...</td>\n",
       "      <td>True</td>\n",
       "      <td>71</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 07:48:44</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-26 07:57:48</td>\n",
       "      <td>6501</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fool gam invad subconscy play hour burn many s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most challenging puzzle games out t...</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 08:43:07</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-18 08:48:29</td>\n",
       "      <td>361</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>on challeng puzzl gam nev unfair mech push rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You have to play the game to understand it and...</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 11:00:45</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-26 17:03:53</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>play gam understand solv puzzl real satisfy ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This game, huh? What a package! \\n\\nRight from...</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 12:27:56</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24 12:00:53</td>\n",
       "      <td>365</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gam huh pack right word go gam lov op menu mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bet you are wondering what this game is actu...</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-04-18 12:38:16</td>\n",
       "      <td>4109</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-15 17:05:17</td>\n",
       "      <td>493</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bet wond gam act lik play wheth wor money revi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  upvoted  \\\n",
       "0  Do not be fooled.\\nThis game will invade your ...     True   \n",
       "1  One of the most challenging puzzle games out t...     True   \n",
       "2  You have to play the game to understand it and...     True   \n",
       "3  This game, huh? What a package! \\n\\nRight from...     True   \n",
       "4  I bet you are wondering what this game is actu...     True   \n",
       "\n",
       "   comment_upvotes  comment_funny_votes  early_review      time_of_review  \\\n",
       "0               71                   41         False 2016-04-18 07:48:44   \n",
       "1               34                   20         False 2016-04-18 08:43:07   \n",
       "2               14                    0         False 2016-04-18 11:00:45   \n",
       "3               10                    2         False 2016-04-18 12:27:56   \n",
       "4               15                    6         False 2016-04-18 12:38:16   \n",
       "\n",
       "   minutes_played  playtime_2weeks         last_played  games_owned  \\\n",
       "0             330                0 2018-11-26 07:57:48         6501   \n",
       "1             245                0 2016-04-18 08:48:29          361   \n",
       "2            1445                0 2016-05-26 17:03:53           67   \n",
       "3             400                0 2017-04-24 12:00:53          365   \n",
       "4            4109                0 2017-02-15 17:05:17          493   \n",
       "\n",
       "   author_reviews  purchased   free  upvotes  total_votes  percent_upvotes  \\\n",
       "0             132      False  False        1            1              1.0   \n",
       "1              10      False  False        2            2              1.0   \n",
       "2               1       True  False        3            3              1.0   \n",
       "3              68      False  False        4            4              1.0   \n",
       "4               3      False  False        5            5              1.0   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  fool gam invad subconscy play hour burn many s...  \n",
       "1  on challeng puzzl gam nev unfair mech push rol...  \n",
       "2  play gam understand solv puzzl real satisfy ev...  \n",
       "3  gam huh pack right word go gam lov op menu mak...  \n",
       "4  bet wond gam act lik play wheth wor money revi...  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = []\n",
    "\n",
    "for review in reviews:\n",
    "    review_tokens = []\n",
    "    cleaned_text = cleanText(review)\n",
    "    cleaned_reviews.append(gen_tokens(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_reviews'] = cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fool gam invad subconscy play hour burn many saus curs comput swear level imposs rag quit stil think day lat start gam attempt level fin solv yel triumph smil start process next level absolv bril sil frust weird amaz fun puzzl gam stop think also mak excel convers start poss convers end wel peopl walk away strange look fac youl brand weirdo profess lov rol saus around ground mind know tru tru beauty steph saus rol walk away smil eag get back gam solv on nef puzzl think week steph saus rol'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_review = reviews[0]\n",
    "\n",
    "\n",
    "cleaned_text = cleanText(single_review)\n",
    "#cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "regex_tokenized = re_tokenizer.tokenize(single_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do',\n",
       " 'not',\n",
       " 'be',\n",
       " 'fooled',\n",
       " 'this',\n",
       " 'game',\n",
       " 'will',\n",
       " 'invade',\n",
       " 'your',\n",
       " 'subconscious',\n",
       " 'you',\n",
       " 'will',\n",
       " 'play',\n",
       " 'for',\n",
       " 'hours',\n",
       " 'you',\n",
       " 'will',\n",
       " 'burn',\n",
       " 'many',\n",
       " 'sausages',\n",
       " 'you',\n",
       " 'will',\n",
       " 'curse',\n",
       " 'at',\n",
       " 'your',\n",
       " 'computer',\n",
       " 'you',\n",
       " 'will',\n",
       " 'swear',\n",
       " 'that',\n",
       " 'level',\n",
       " 'is',\n",
       " 'impossible',\n",
       " 'you',\n",
       " 'will',\n",
       " 'rage',\n",
       " 'quit',\n",
       " 'you',\n",
       " 'will',\n",
       " 'still',\n",
       " 'be',\n",
       " 'thinking',\n",
       " 'about',\n",
       " 'it',\n",
       " 'days',\n",
       " 'later',\n",
       " 'you',\n",
       " 'will',\n",
       " 'start',\n",
       " 'the',\n",
       " 'game',\n",
       " 'again',\n",
       " 'and',\n",
       " 'attempt',\n",
       " 'a',\n",
       " 'level',\n",
       " 'again',\n",
       " 'you',\n",
       " 'will',\n",
       " 'finally',\n",
       " 'solve',\n",
       " 'it',\n",
       " 'you',\n",
       " 'will',\n",
       " 'yell',\n",
       " 'in',\n",
       " 'triumph',\n",
       " 'and',\n",
       " 'smile',\n",
       " 'then',\n",
       " 'you',\n",
       " 'll',\n",
       " 'start',\n",
       " 'the',\n",
       " 'process',\n",
       " 'again',\n",
       " 'on',\n",
       " 'the',\n",
       " 'next',\n",
       " 'level',\n",
       " 'it',\n",
       " 's',\n",
       " 'absolutely',\n",
       " 'brilliant',\n",
       " 'and',\n",
       " 'silly',\n",
       " 'and',\n",
       " 'frustrating',\n",
       " 'and',\n",
       " 'weird',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'fun',\n",
       " 'puzzle',\n",
       " 'game',\n",
       " 'that',\n",
       " 'you',\n",
       " 'll',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'thinking',\n",
       " 'about',\n",
       " 'it',\n",
       " 's',\n",
       " 'will',\n",
       " 'also',\n",
       " 'make',\n",
       " 'an',\n",
       " 'excellent',\n",
       " 'conversation',\n",
       " 'starter',\n",
       " 'and',\n",
       " 'possibly',\n",
       " 'conversation',\n",
       " 'ender',\n",
       " 'as',\n",
       " 'well',\n",
       " 'with',\n",
       " 'people',\n",
       " 'walking',\n",
       " 'away',\n",
       " 'with',\n",
       " 'strange',\n",
       " 'looks',\n",
       " 'on',\n",
       " 'their',\n",
       " 'face',\n",
       " 'you',\n",
       " 'll',\n",
       " 'be',\n",
       " 'branded',\n",
       " 'a',\n",
       " 'weirdo',\n",
       " 'as',\n",
       " 'you',\n",
       " 'profess',\n",
       " 'your',\n",
       " 'love',\n",
       " 'of',\n",
       " 'rolling',\n",
       " 'sausages',\n",
       " 'around',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'but',\n",
       " 'you',\n",
       " 'won',\n",
       " 't',\n",
       " 'mind',\n",
       " 'because',\n",
       " 'you',\n",
       " 'll',\n",
       " 'know',\n",
       " 'the',\n",
       " 'truth',\n",
       " 'the',\n",
       " 'true',\n",
       " 'beauty',\n",
       " 'that',\n",
       " 'is',\n",
       " 'stephen',\n",
       " 's',\n",
       " 'sausage',\n",
       " 'roll',\n",
       " 'and',\n",
       " 'you',\n",
       " 'll',\n",
       " 'walk',\n",
       " 'away',\n",
       " 'from',\n",
       " 'them',\n",
       " 'smiling',\n",
       " 'to',\n",
       " 'yourself',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'game',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'that',\n",
       " 'one',\n",
       " 'nefarious',\n",
       " 'puzzle',\n",
       " 'that',\n",
       " 'you',\n",
       " 've',\n",
       " 'been',\n",
       " 'thinking',\n",
       " 'about',\n",
       " 'all',\n",
       " 'week',\n",
       " 'stephen',\n",
       " 's',\n",
       " 'sausage',\n",
       " 'roll']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_review = reviews.iloc[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "ws_tokenizer = WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_tokenized = ws_tokenizer.tokenize(single_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download('stopwords') # if stopwords haven't been used before\n",
    "\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_cleaned_tokens = []\n",
    "\n",
    "for token in ws_tokenized:\n",
    "    if token not in stopwords:\n",
    "        ws_cleaned_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'single_review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64deea51ba0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstemmed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_review_stemmed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## stemmed tokens or stemmed text for vectorization?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#stemmed_tokens = tokenize_review.stem_tokens(ws_tokenized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'single_review' is not defined"
     ]
    }
   ],
   "source": [
    "'''ws_tokenized = tokenize_review.tokenize(single_review)\n",
    "stemmed_text = tokenize_review.full_review_stemmed(ws_tokenized)\n",
    "\n",
    "## stemmed tokens or stemmed text for vectorization?\n",
    "#stemmed_tokens = tokenize_review.stem_tokens(ws_tokenized)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_reviews = []\n",
    "\n",
    "for review in reviews:\n",
    "    ws_tokenized = tokenize_review.tokenize(review)\n",
    "    stemmed_text = tokenize_review.full_review_stemmed(ws_tokenized)\n",
    "    \n",
    "    stemmed_reviews.append(stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed_review'] = stemmed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '100', '11', '12', '132', '15', '15min', '16', '174', '19', '1990s', '1x1x1', '20', '2016', '2017', '2018', '21', '22', '220', '23gbp', '24', '25', '28', '29', '2d', '2nd', '2x1x1', '30', '31', '31803828', '32', '35', '352649', '36', '37', '3d', '3rds', '40', '400iq', '42', '45', '48', '4th', '50', '60', '64', '70', '80', '86', '87', '897', '90', '90s', '99', '_difficult_', 'aaa', 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh', 'aback', 'abil', 'abilities', 'ability', 'abl', 'abound', 'about', 'abrupt', 'absolut', 'absolute', 'absolutely', 'abstract', 'absurd', 'abysmal', 'access', 'accessible', 'accid', 'accident', 'acclaim', 'acclimat', 'accommod', 'accompaniment', 'accomplish', 'accord', 'account', 'accumul', 'accur', 'accustom', 'achiev', 'achieve', 'achievement', 'acknowledg', 'across', 'acting', 'action', 'activ', 'activity', 'actual', 'acuiti', 'ad', 'add', 'added', 'addict', 'addictive', 'addit', 'additions', 'additon', 'adept', 'adequ', 'adher', 'adit', 'adjust', 'admir', 'admit', 'ador', 'advanc', 'advantag', 'adventur', 'adventurer', 'advic', 'advice', 'aerodynam', 'aesthet', 'aesthetic', 'aesthetically', 'af', 'affect', 'aforement', 'afraid', 'after', 'again', 'against', 'age', 'aggravating', 'ago', 'agon', 'agonizingly', 'agre', 'ah', 'aha', 'ahah', 'ahead', 'ain', 'air', 'aka', 'akin', 'alarm', 'album', 'alexand', 'algorithm', 'align', 'alike', 'alive', 'all', 'allegory', 'allevi', 'alliev', 'alliter', 'allow', 'almost', 'alon', 'alone', 'along', 'alreadi', 'alright', 'also', 'alter', 'altern', 'alternate', 'although', 'alway', 'always', 'am', 'amaz', 'amazed', 'amazing', 'ambient', 'ambiti', 'ambitious', 'amend', 'among', 'amount', 'an', 'analog', 'analogy', 'anchor', 'ancient', 'and', 'anderson', 'angl', 'angle', 'angri', 'angry', 'ani', 'anim', 'animal', 'annoy', 'annoyance', 'annoyed', 'annoying', 'anoth', 'another', 'anoyying', 'answer', 'answers', 'antialias', 'antichamber', 'anticip', 'anwer', 'any', 'anybodi', 'anybody', 'anyhow', 'anymore', 'anyon', 'anyth', 'anything', 'anyway', 'anyways', 'anywher', 'apace', 'apart', 'apathi', 'apolog', 'appal', 'appar', 'apparit', 'appeal', 'appealing', 'appear', 'appearance', 'appet', 'appli', 'applic', 'apply', 'appreci', 'approach', 'approachable', 'appropri', 'appropriately', 'apreci', 'apt', 'arbitrari', 'arbitrarili', 'arbitrary', 'are', 'area', 'areas', 'aren', 'argh', 'aris', 'arise', 'arm', 'around', 'arrang', 'arriv', 'arrow', 'arrowkey', 'art', 'artful', 'artifici', 'artwork', 'as', 'ascertain', 'asid', 'aside', 'ask', 'asked', 'asks', 'aspect', 'ass', 'assault', 'asset', 'assort', 'assum', 'asthet', 'astonish', 'astonishingly', 'astound', 'astounding', 'at', 'ate', 'atempt', 'atmospher', 'atmosphere', 'atomix', 'attached', 'attack', 'attain', 'attempt', 'attempts', 'attent', 'attitud', 'attribut', 'audienc', 'audience', 'audio', 'autistic', 'auto', 'automat', 'avail', 'available', 'avatar', 'avenu', 'averag', 'average', 'avers', 'avoid', 'aw', 'awaits', 'awar', 'award', 'awards', 'away', 'awe', 'awesom', 'awhil', 'awhile', 'awkward', 'awok', 'axi', 'babel', 'babi', 'back', 'backbone', 'background', 'backward', 'backwards', 'bad', 'baffl', 'baffling', 'bag', 'bait', 'balanc', 'ball', 'ballpark', 'balls', 'baloney', 'ban', 'bang', 'bare', 'barebon', 'barrier', 'bas', 'base', 'bash', 'basi', 'basic', 'basically', 'basis', 'bask', 'battl', 'bawl', 'bbc', 'bbq', 'be', 'beach', 'beam', 'bear', 'beat', 'beaten', 'beaut', 'beauti', 'beautiful', 'beauty', 'becam', 'becaus', 'because', 'becom', 'bed', 'beep', 'beers', 'befor', 'before', 'beg', 'begin', 'beginner', 'beginning', 'behind', 'behold', 'believ', 'believe', 'below', 'bend', 'bending', 'beneath', 'benefit', 'best', 'bet', 'beta', 'betrayed', 'better', 'between', 'beware', 'beyond', 'biased', 'big', 'bigger', 'biggest', 'binari', 'bit', 'bite', 'bits', 'bitter', 'bizarr', 'bizzarr', 'blank', 'blanket', 'blast', 'blend', 'blew', 'blind', 'blindfold', 'bliss', 'block', 'blocker', 'blocki', 'blocks', 'blogger', 'blond', 'blood', 'bloodi', 'blow', 'blowing', 'blown', 'blurred', 'board', 'bob', 'bodi', 'boggling', 'boil', 'bomb', 'bone', 'boop', 'boot', 'bore', 'bored', 'boring', 'boss', 'both', 'bother', 'bottom', 'bought', 'bounc', 'bound', 'boundari', 'box', 'boy', 'braid', 'brain', 'brainbreaking', 'brainpow', 'brand', 'bratti', 'bread', 'break', 'breaker', 'breakthrough', 'breath', 'breathtaking', 'breed', 'breez', 'bretfast', 'bridg', 'brightest', 'brillianc', 'brilliant', 'bring', 'british', 'broader', 'broken', 'brought', 'brown', 'bruce', 'brush', 'brutal', 'brute', 'btw', 'buck', 'bucks', 'budget', 'build', 'built', 'bulls', 'bump', 'bun', 'bunch', 'bundl', 'bundle', 'bundles', 'buri', 'burn', 'burned', 'burner', 'burners', 'burnt', 'busi', 'business', 'busywork', 'but', 'butt', 'butter', 'buttload', 'button', 'buttons', 'buy', 'by', 'bypass', 'cabl', 'california', 'call', 'calm', 'came', 'camera', 'campiness', 'can', 'cancer', 'cannot', 'canon', 'cant', 'capabl', 'capac', 'capibl', 'captur', 'car', 'cardboard', 'care', 'carefully', 'cares', 'carri', 'carv', 'case', 'cash', 'cast', 'casual', 'catagori', 'catch', 'catchi', 'categori', 'cater', 'caught', 'caus', 'caution', 'ceil', 'celebration', 'cell', 'cells', 'cent', 'centre', 'cerebr', 'certain', 'cevapi', 'challeng', 'challenge', 'challenged', 'challenges', 'challenging', 'champ', 'chanc', 'chance', 'chang', 'change', 'changes', 'channel', 'chapter', 'charact', 'character', 'characterisation', 'characterist', 'chariti', 'charm', 'charming', 'cheap', 'cheaper', 'cheapest', 'cheat', 'check', 'checking', 'checkpoint', 'chees', 'chef', 'cherri', 'chew', 'child', 'chill', 'chip', 'choic', 'choice', 'choke', 'choos', 'chore', 'christ', 'chunk', 'ci', 'circle', 'cite', 'citizen', 'ck', 'claim', 'clariti', 'clarity', 'class', 'classic', 'claustrophob', 'clear', 'clever', 'clich', 'click', 'clicks', 'cliff', 'climat', 'climb', 'clip', 'clock', 'clockwis', 'clockwise', 'close', 'closer', 'cloud', 'clover', 'clown', 'clue', 'clueless', 'clunki', 'clunky', 'cnd', 'coal', 'coddl', 'code', 'coffee', 'cohesive', 'cold', 'collect', 'color', 'colour', 'colours', 'columns', 'com', 'combin', 'come', 'comfort', 'comic', 'coming', 'comment', 'commerci', 'commitment', 'common', 'communic', 'communiti', 'compact', 'compar', 'comparison', 'comparisons', 'compelling', 'competit', 'complain', 'complaint', 'complet', 'complete', 'completed', 'completionist', 'complex', 'complexifi', 'complexities', 'complexity', 'complic', 'complicated', 'compon', 'compos', 'comprehend', 'compris', 'comput', 'computer', 'concentr', 'concentrated', 'concept', 'concepts', 'conceptu', 'conceptually', 'concis', 'conclud', 'conclus', 'conclusion', 'concrete', 'condescending', 'confid', 'confidence', 'config', 'configur', 'configuration', 'confin', 'conflict', 'conform', 'confound', 'confront', 'confus', 'confusing', 'congratulations', 'congruous', 'connect', 'connection', 'conquer', 'cons', 'consequ', 'consid', 'consider', 'consist', 'consistant', 'constant', 'constantly', 'constrain', 'constraint', 'construct', 'construction', 'consum', 'consumption', 'contact', 'contain', 'content', 'contest', 'context', 'contextu', 'continu', 'continue', 'contradictori', 'contrast', 'contribut', 'control', 'controlls', 'controls', 'conundrums', 'conveni', 'convent', 'convers', 'convey', 'convinc', 'convinced', 'cook', 'cookabl', 'cooked', 'cooki', 'cooking', 'cool', 'copi', 'cor', 'core', 'correct', 'correspond', 'corridor', 'cos', 'cost', 'could', 'couldn', 'count', 'counter', 'countless', 'countri', 'coupl', 'courag', 'courage', 'cours', 'course', 'cov', 'cover', 'crack', 'craft', 'crafted', 'crappi', 'crappy', 'crash', 'crashed', 'crass', 'crate', 'crave', 'crazi', 'crazy', 'creat', 'created', 'creativ', 'creative', 'creator', 'credit', 'creepy', 'cri', 'crimin', 'crisi', 'criteria', 'critic', 'crop', 'crossword', 'crosswords', 'crowd', 'crown', 'crude', 'crumbs', 'crush', 'cryptic', 'cube', 'cubes', 'culdnt', 'culmin', 'cultiv', 'cumbersom', 'cunning', 'cup', 'curat', 'curator', 'curiosity', 'current', 'curs', 'curv', 'curve', 'curves', 'custom', 'cut', 'cute', 'cycl', 'cycle', 'cylind', 'dam', 'damn', 'dang', 'dare', 'dark', 'dashed', 'data', 'date', 'daunt', 'day', 'days', 'dead', 'deadlock', 'deadly', 'deal', 'dealt', 'decade', 'decades', 'deceiv', 'decent', 'decep', 'decept', 'decid', 'decide', 'decis', 'decontextu', 'dedic', 'deduction', 'deep', 'deepli', 'defeat', 'defin', 'definet', 'definit', 'degre', 'deli', 'deliber', 'delicacy', 'delici', 'delicious', 'delight', 'deliv', 'delug', 'delv', 'dem', 'demand', 'demo', 'demonstr', 'dens', 'dense', 'depend', 'depli', 'depress', 'depriv', 'depth', 'deriv', 'descend', 'describ', 'descript', 'description', 'desert', 'deserv', 'deserves', 'design', 'designed', 'designer', 'desir', 'despis', 'despit', 'destructoid', 'detail', 'details', 'determin', 'deterr', 'detract', 'dev', 'develop', 'developer', 'developers', 'devilish', 'devious', 'dialog', 'dialogue', 'diamond', 'dick', 'did', 'didn', 'die', 'diehard', 'differ', 'different', 'difficult', 'difficulti', 'difficulties', 'difficulty', 'dig', 'digest', 'dimens', 'dimension', 'dip', 'direct', 'direction', 'directions', 'directly', 'directori', 'disables', 'disagree', 'disappear', 'disappoint', 'disappointed', 'disast', 'discard', 'disclosure', 'discord', 'discourag', 'discov', 'discover', 'discovered', 'discoveri', 'discovery', 'discreet', 'discret', 'discuss', 'dishonored', 'disjoint', 'dislik', 'dismiss', 'display', 'dispos', 'disposal', 'disrupt', 'disservic', 'disservice', 'distanc', 'distance', 'distil', 'distinct', 'distinguish', 'distort', 'distract', 'disturbing', 'dive', 'divers', 'dividend', 'divis', 'dlc', 'do', 'doabl', 'doable', 'dobra', 'doe', 'does', 'doesn', 'dog', 'doing', 'dollar', 'dollars', 'domino', 'don', 'done', 'dont', 'doozy', 'dose', 'doubt', 'dough', 'down', 'downgrade', 'download', 'downs', 'downsid', 'downtim', 'downvot', 'dozen', 'dr', 'drag', 'dragon', 'dramat', 'dramatic', 'draw', 'drawn', 'dread', 'dreadful', 'dream', 'dress', 'dri', 'drill', 'drip', 'drive', 'drm', 'drop', 'drove', 'drug', 'drumlin', 'drunk', 'dude', 'due', 'duke', 'dumb', 'dumbass', 'dumber', 'dump', 'duper', 'duration', 'dwell', 'dynam', 'each', 'eager', 'earli', 'earlier', 'earliest', 'earn', 'earth', 'eas', 'ease', 'easi', 'easier', 'easiest', 'easili', 'easy', 'eat', 'eccentr', 'edges', 'edibl', 'edit', 'editor', 'educ', 'eery', 'effect', 'effectively', 'effects', 'effort', 'eggs', 'ego', 'eheh', 'eighteen', 'eighty', 'either', 'elabor', 'eleg', 'elegance', 'elegant', 'element', 'elements', 'eleven', 'els', 'else', 'eludied', 'embed', 'embrac', 'emerg', 'emot', 'emphas', 'emphasi', 'employ', 'empti', 'empty', 'enamor', 'encapsulating', 'encount', 'encourag', 'encouraged', 'encunt', 'end', 'endear', 'endearing', 'ender', 'endgam', 'ending', 'endless', 'endors', 'energi', 'engag', 'engaging', 'engin', 'english', 'engross', 'enigmat', 'enigmatic', 'enjoy', 'enjoyable', 'enjoyment', 'enlighten', 'enorm', 'enough', 'enter', 'entertain', 'enthusiast', 'enthusiasts', 'entir', 'environ', 'environment', 'environmental', 'epic', 'epiphani', 'epiphany', 'epitom', 'eponym', 'equal', 'equip', 'error', 'eschew', 'especi', 'essenc', 'essens', 'essenti', 'essentially', 'establish', 'etc', 'etern', 'euphoria', 'eur', 'eureka', 'even', 'eventu', 'eventually', 'ever', 'everest', 'everi', 'every', 'everybodi', 'everybody', 'everyday', 'everyon', 'everyone', 'everyth', 'everything', 'everywher', 'everywhere', 'evil', 'evok', 'evolut', 'evolv', 'exact', 'exactly', 'exager', 'exaggerating', 'exaggeration', 'examin', 'exampl', 'example', 'exaust', 'exceed', 'excel', 'excellence', 'excellent', 'except', 'exceptional', 'exceptions', 'excit', 'exciting', 'exclud', 'exclusively', 'excpect', 'excruci', 'excus', 'execut', 'execute', 'executed', 'exercis', 'exhaust', 'exhausted', 'exhausting', 'exist', 'existed', 'existenti', 'existing', 'exists', 'exit', 'expand', 'expect', 'expectations', 'expecting', 'expeienc', 'expend', 'expens', 'expensive', 'experi', 'experienc', 'experience', 'experienced', 'experiment', 'experimental', 'experimentation', 'experimenting', 'expert', 'expertis', 'expertise', 'explain', 'explan', 'explanation', 'explanations', 'explicit', 'exploit', 'exploits', 'explor', 'exploration', 'explore', 'explored', 'exploring', 'expos', 'exposit', 'exquisit', 'extend', 'extens', 'extent', 'extern', 'extra', 'extract', 'extran', 'extrem', 'extreme', 'extremes', 'eye', 'eyes', 'f_uck', 'face', 'facin', 'facing', 'fact', 'factorio', 'factory', 'fail', 'failing', 'failur', 'failure', 'faint', 'fair', 'fairest', 'faith', 'fall', 'fals', 'fame', 'famili', 'familiar', 'familiarity', 'fan', 'fanat', 'fanatic', 'fanatics', 'fanbas', 'fanci', 'fans', 'fantast', 'fantastic', 'far', 'fashion', 'fast', 'faster', 'fate', 'fault', 'favor', 'favorit', 'favorite', 'favour', 'favourit', 'fawn', 'feared', 'feat', 'featur', 'features', 'feebl', 'feed', 'feel', 'feeling', 'feint', 'fell', 'felt', 'fenc', 'fence', 'fend', 'fermi', 'fetish', 'feustrat', 'few', 'fez', 'fi', 'fidel', 'field', 'fiendish', 'fifth', 'fight', 'figur', 'file', 'fill', 'filler', 'fillery', 'fillets', 'fin', 'final', 'finale', 'finally', 'find', 'fine', 'finess', 'finest', 'finish', 'finished', 'finite', 'fir', 'fire', 'firelink', 'firm', 'first', 'firstly', 'fish', 'fist', 'fit', 'five', 'fix', 'fixed', 'flabergast', 'flail', 'flak', 'flash', 'flat', 'flatter', 'flavor', 'flawless', 'fledg', 'flex', 'flip', 'float', 'flood', 'floor', 'flow', 'flowers', 'fluctuat', 'fluff', 'fluid', 'fo', 'foam', 'foami', 'focus', 'focused', 'foist', 'follow', 'followups', 'follw', 'font', 'fonts', 'food', 'fool', 'fooled', 'for', 'forc', 'force', 'forced', 'foreign', 'foremost', 'forese', 'forev', 'forever', 'forget', 'forgiv', 'forgo', 'forgot', 'forgotten', 'fork', 'forkin', 'forklift', 'forks', 'form', 'former', 'formula', 'forrag', 'forth', 'fortun', 'fortunately', 'forward', 'found', 'four', 'fourth', 'frame', 'frank', 'frankly', 'fre', 'freak', 'freakin', 'free', 'freedom', 'frell', 'frequent', 'fresh', 'fri', 'frick', 'friend', 'friendly', 'friends', 'frills', 'from', 'front', 'frown', 'fruit', 'frustrat', 'frustrated', 'frustrating', 'frustration', 'frustur', 'fuck', 'fulfil', 'full', 'fulli', 'fumbl', 'fun', 'function', 'fundament', 'funnel', 'funni', 'funnier', 'further', 'furthermore', 'futur', 'future', 'fuzzi', 'fyi', 'gaben', 'gain', 'gam', 'gambit', 'game', 'gameplay', 'gamer', 'gamers', 'games', 'gaming', 'garbag', 'garden', 'gate', 'gateway', 'gaug', 'gauntlet', 'gave', 'gawds', 'gaze', 'gel', 'gem', 'gener', 'general', 'generally', 'generat', 'generated', 'generic', 'genial', 'genious', 'genius', 'genr', 'genre', 'gentl', 'genuin', 'geometri', 'german', 'get', 'gete', 'getting', 'ghost', 'giant', 'gift', 'gigant', 'gimmick', 'gimmicks', 'git', 'give', 'given', 'glad', 'glanc', 'glance', 'glean', 'glimps', 'glitter', 'glory', 'glow', 'go', 'goal', 'god', 'goddamn', 'goe', 'goes', 'going', 'gold', 'golden', 'gone', 'gonna', 'good', 'goodness', 'googl', 'got', 'goti', 'gotten', 'govern', 'gra', 'grab', 'grace', 'gradient', 'gradual', 'grail', 'grain', 'grander', 'grandma', 'grant', 'graphic', 'graphics', 'grappl', 'grasp', 'grass', 'grate', 'gratif', 'greasy', 'great', 'greater', 'greatest', 'greatness', 'greet', 'grey', 'grid', 'gridlock', 'gril', 'grill', 'grilled', 'grilles', 'grilling', 'grills', 'grip', 'gripe', 'gripped', 'ground', 'group', 'grow', 'grunt', 'guarante', 'guard', 'gud', 'guess', 'guesses', 'guid', 'guidance', 'guides', 'guy', 'h1', 'ha', 'habit', 'hacker', 'had', 'haha', 'hair', 'half', 'halfway', 'hallmark', 'halting', 'hana', 'hand', 'handcraft', 'handholding', 'handicap', 'handicapped', 'handl', 'handle', 'hands', 'hannib', 'hanoi', 'happen', 'happend', 'happened', 'happens', 'happi', 'happy', 'hard', 'hardcor', 'harder', 'hardest', 'hards', 'hardset', 'hardwar', 'harsh', 'has', 'hat', 'hate', 'haunt', 'have', 'he', 'head', 'heap', 'hear', 'heard', 'hearing', 'heart', 'heartedly', 'heavili', 'heck', 'heft', 'hefti', 'height', 'held', 'hell', 'help', 'helpful', 'helps', 'here', 'heritage', 'herring', 'herself', 'hesit', 'hi', 'hidden', 'hide', 'hideously', 'high', 'higher', 'highest', 'highlight', 'highly', 'him', 'hindrance', 'hint', 'hints', 'hiss', 'histor', 'histori', 'history', 'hit', 'hold', 'holdi', 'holding', 'holds', 'hole', 'holi', 'home', 'honed', 'honest', 'honestly', 'hook', 'hooked', 'hope', 'hopefully', 'hopeless', 'horizontal', 'horrid', 'horror', 'hot', 'hour', 'hours', 'how', 'howev', 'however', 'http', 'https', 'huge', 'huh', 'human', 'humbl', 'humblebundle', 'humorous', 'hunch', 'hundr', 'hunger', 'hungri', 'hungry', 'hur', 'hurdl', 'hurdle', 'hurl', 'hurri', 'hurt', 'hurts', 'hyper', 'hypnot', 'hypothes', 'iceberg', 'idea', 'ideas', 'idiot', 'if', 'ignor', 'illustrated', 'imag', 'images', 'imagin', 'imagine', 'immacul', 'immedi', 'immediately', 'immens', 'imo', 'impact', 'impati', 'impl', 'impli', 'implic', 'impliment', 'import', 'importantly', 'imposs', 'impossble', 'impossible', 'impractical', 'impress', 'impressive', 'improv', 'in', 'inability', 'inabl', 'inaccess', 'incent', 'incess', 'inch', 'inclin', 'includ', 'included', 'inconsequenti', 'inconsist', 'incorpor', 'incorrect', 'increas', 'incred', 'incredbil', 'incredible', 'increment', 'increpar', 'increpare', 'inde', 'indeed', 'indefinitely', 'independ', 'indescribable', 'indi', 'indie', 'individu', 'industri', 'inevit', 'infam', 'inferior', 'infinifactori', 'infinit', 'inflation', 'influenc', 'influence', 'inform', 'information', 'infuri', 'infuriating', 'ingeni', 'ingenious', 'init', 'initi', 'innoc', 'innocu', 'innov', 'input', 'inputs', 'insan', 'insane', 'inscrutable', 'insid', 'inside', 'insight', 'inspir', 'inspiration', 'instanc', 'instance', 'instant', 'instantly', 'instead', 'instruct', 'instructions', 'integr', 'intellectu', 'intellig', 'intelligence', 'intend', 'intended', 'intens', 'intensity', 'intent', 'intentional', 'interact', 'interconnect', 'interest', 'interesting', 'interfac', 'interfer', 'internet', 'interplay', 'interpret', 'interspers', 'intertwin', 'interview', 'intimid', 'intimidating', 'into', 'intrest', 'intricaci', 'intrigu', 'intrins', 'introduc', 'introduced', 'introduct', 'intuat', 'intuit', 'intuitive', 'intuitively', 'invad', 'invalu', 'invent', 'invest', 'invis', 'involv', 'inward', 'io', 'irksom', 'irl', 'irrelev', 'irrelevant', 'is', 'ise', 'island', 'islands', 'isnt', 'issu', 'issue', 'it', 'itch', 'item', 'iter', 'iterative', 'itself', 'itselt', 'j0bs', 'jade', 'jam', 'japanes', 'jelli', 'jenga', 'jewel', 'jigsaws', 'job', 'johnathan', 'jok', 'joke', 'jokes', 'jon', 'jonathan', 'joseph', 'journey', 'joy', 'joyous', 'judgement', 'juggl', 'juic', 'juici', 'jump', 'jumps', 'just', 'justifi', 'justifiable', 'justifiably', 'kane', 'kbwnyiwczn4', 'keep', 'keeper', 'kept', 'ketchup', 'key', 'keyboard', 'keys', 'keyword', 'kick', 'kid', 'kids', 'killer', 'kind', 'kinglink', 'kino', 'knackvurst', 'knew', 'knight', 'knobs', 'knock', 'knot', 'know', 'knowledg', 'knowledge', 'known', 'knows', 'kofta', 'l33t', 'label', 'labour', 'lack', 'lacklustre', 'ladder', 'ladders', 'laid', 'land', 'language', 'larg', 'larger', 'last', 'lastly', 'latch', 'late', 'later', 'latest', 'latter', 'lauded', 'laugh', 'laughable', 'launch', 'laundri', 'lavell', 'lavelle', 'law', 'laws', 'lay', 'layer', 'layman', 'lead', 'lean', 'leap', 'leaps', 'learn', 'learned', 'least', 'leathery', 'leav', 'lecter', 'left', 'legendari', 'legitim', 'lemma', 'lend', 'length', 'lengthi', 'lengths', 'less', 'lesser', 'lesson', 'lest', 'let', 'letsplay', 'level', 'levelling', 'levels', 'library', 'lie', 'lies', 'life', 'lifetim', 'light', 'lightly', 'lik', 'like', 'likes', 'limbo', 'limit', 'limited', 'limitless', 'limits', 'line', 'linear', 'lines', 'link', 'linux', 'liquids', 'list', 'listen', 'liter', 'literally', 'littl', 'little', 'live', 'll', 'lo', 'load', 'locat', 'location', 'lock', 'lode', 'log', 'logic', 'logical', 'logically', 'logician', 'logist', 'logo', 'lol', 'lolo', 'long', 'longer', 'longev', 'look', 'looker', 'looking', 'loos', 'lord', 'lore', 'lose', 'lost', 'lot', 'lots', 'loud', 'love', 'lover', 'lovers', 'low', 'luck', 'luckili', 'ludicr', 'lunch', 'mad', 'madden', 'made', 'magazine', 'magic', 'magician', 'magnificent', 'magnifici', 'maillard', 'main', 'major', 'make', 'making', 'man', 'manag', 'mandat', 'maneouv', 'maneuv', 'maneuver', 'maneuveur', 'manhandl', 'mani', 'mania', 'manipul', 'manner', 'many', 'map', 'marbl', 'margin', 'mario', 'mark', 'market', 'marketing', 'marvel', 'mask', 'massiv', 'mast', 'master', 'masterclass', 'masterful', 'masteri', 'masterpiec', 'masterpiece', 'match', 'materi', 'materials', 'math', 'mathematician', 'matter', 'matters', 'maximum', 'may', 'mayb', 'maybe', 'maze', 'me', 'mean', 'meaning', 'means', 'meant', 'meat', 'meati', 'meaty', 'mechan', 'mechancis', 'mechanic', 'mechanically', 'mechanics', 'mechanism', 'meet', 'meh', 'mellow', 'melt', 'melter', 'member', 'meme', 'memori', 'mental', 'mention', 'mentioned', 'menu', 'menus', 'merci', 'merciless', 'mere', 'mesmer', 'mess', 'messag', 'meta', 'metal', 'metaphor', 'metaphorically', 'method', 'meticul', 'mi', 'microworld', 'mid', 'midair', 'middl', 'middle', 'might', 'mild', 'milk', 'million', 'min', 'mind', 'mindbend', 'mindblow', 'mindblown', 'mindboggl', 'mine', 'minecraft', 'minim', 'minimal', 'minimalist', 'minimalistically', 'minimum', 'minor', 'minut', 'minutes', 'mise', 'miser', 'misguid', 'misl', 'miss', 'missing', 'mistak', 'mistake', 'mistaken', 'mistakes', 'misunderstand', 'misunderstood', 'mix', 'mixtur', 'mmmm', 'mmmmmmmm', 'moan', 'moani', 'moat', 'mobil', 'mock', 'moder', 'modern', 'mods', 'mold', 'moment', 'moments', 'money', 'month', 'monthly', 'months', 'moral', 'more', 'moreso', 'morn', 'moron', 'morph', 'morsel', 'mosli', 'most', 'motion', 'motiv', 'mount', 'mous', 'mouth', 'move', 'movement', 'moves', 'moveset', 'movie', 'moving', 'mr', 'much', 'muck', 'muddy', 'mull', 'multipl', 'multitud', 'mumbl', 'mundan', 'music', 'must', 'mute', 'mutter', 'my', 'myself', 'mysteri', 'mystery', 'mystifying', 'nail', 'nam', 'name', 'narrat', 'narrative', 'narrow', 'nathan', 'natur', 'natural', 'naturally', 'nature', 'navig', 'near', 'neat', 'necessari', 'necessarili', 'necessary', 'need', 'needed', 'needle', 'needless', 'nefari', 'negat', 'negative', 'neither', 'nerd', 'nervous', 'nes', 'nest', 'neutral', 'never', 'new', 'newest', 'newfound', 'newgrounds', 'newli', 'next', 'nice', 'nicely', 'nich', 'night', 'nightmar', 'nightmarish', 'nitpick', 'nitpicking', 'no', 'nobodi', 'node', 'noggin', 'noise', 'non', 'nondescript', 'none', 'nonsense', 'noodle', 'nope', 'normal', 'nostalgia', 'not', 'notabl', 'notch', 'note', 'noth', 'nothing', 'notic', 'notice', 'notion', 'notori', 'novel', 'novelty', 'now', 'nowher', 'nuanc', 'nudg', 'nukem', 'number', 'numbing', 'numer', 'nut', 'obes', 'obfusc', 'object', 'objects', 'oblig', 'oblong', 'obnoxi', 'obnoxious', 'obscur', 'obscure', 'observ', 'obsess', 'obstacl', 'obstacles', 'obtain', 'obtrus', 'obtus', 'obvious', 'ocarina', 'occasion', 'occasions', 'occur', 'ocean', 'odd', 'of', 'off', 'offend', 'offer', 'offici', 'offline', 'offput', 'often', 'oftentim', 'oh', 'oi', 'ok', 'okay', 'old', 'olist', 'omg', 'omnia', 'on', 'onc', 'once', 'one', 'ones', 'ongo', 'onli', 'onlin', 'only', 'onscreen', 'onto', 'onward', 'open', 'oper', 'opera', 'opinion', 'oppisit', 'opportun', 'opt', 'option', 'options', 'or', 'order', 'ordinarili', 'organ', 'orient', 'orientation', 'origin', 'orion', 'other', 'others', 'otherwis', 'otherwise', 'otherworld', 'ounc', 'oustid', 'out', 'outcome', 'outlet', 'outright', 'outsid', 'outside', 'outsiders', 'outsurv', 'outweigh', 'over', 'overal', 'overall', 'overcom', 'overcome', 'overconsum', 'overcook', 'overexert', 'overhang', 'overlook', 'overplay', 'overpriced', 'overrated', 'overshadow', 'oversight', 'overstay', 'overthink', 'overthinking', 'overwhelm', 'overwhelming', 'overworld', 'owe', 'own', 'oww', 'pace', 'pack', 'packag', 'package', 'page', 'paid', 'pain', 'painful', 'painstaking', 'pale', 'palin', 'pan', 'pang', 'paper', 'paradox', 'parallel', 'park', 'parrot', 'part', 'particl', 'particular', 'parts', 'pass', 'passable', 'passage', 'passion', 'past', 'pastry', 'pasture', 'path', 'patienc', 'patience', 'patient', 'paus', 'pay', 'payoff', 'peac', 'peace', 'peak', 'peers', 'pen', 'penalty', 'penny', 'peopl', 'people', 'per', 'perfect', 'perfection', 'perfectly', 'perform', 'perhap', 'period', 'perman', 'perpendicular', 'perplex', 'perplexing', 'persever', 'persevere', 'persist', 'person', 'personality', 'personally', 'peski', 'phantom', 'phases', 'phenomenal', 'philosophies', 'photorealist', 'photoshop', 'phtml', 'physic', 'physics', 'piano', 'pick', 'pictur', 'picture', 'piec', 'pieces', 'pig', 'pigs', 'pile', 'pilgram', 'pillar', 'pink', 'pipocafacemc', 'piqu', 'piss', 'piti', 'pixel', 'pizza', 'plac', 'place', 'placed', 'places', 'plague', 'plain', 'plan', 'planner', 'planning', 'plaqu', 'plaques', 'plastic', 'platform', 'play', 'played', 'player', 'players', 'playground', 'playing', 'playstyle', 'playthrough', 'playtim', 'playtime', 'pleas', 'pleasur', 'plenti', 'plot', 'pls', 'plus', 'poetic', 'point', 'pointless', 'points', 'poke', 'poli', 'polish', 'polished', 'polygon', 'poni', 'pop', 'popular', 'popup', 'pork', 'portal', 'poses', 'posit', 'positions', 'positive', 'possibilit', 'possibilities', 'possibl', 'possible', 'possibly', 'postpon', 'potenti', 'potential', 'power', 'powerups', 'pr', 'practic', 'practical', 'practices', 'prais', 'praise', 'pre', 'precious', 'precis', 'precisely', 'preconcept', 'predecessor', 'predefin', 'predictable', 'prefer', 'premis', 'premise', 'premium', 'prepar', 'present', 'presentation', 'presented', 'preserv', 'press', 'presum', 'pretend', 'pretti', 'prevent', 'previous', 'previously', 'price', 'pricetag', 'pricey', 'pride', 'primitive', 'principl', 'principle', 'principles', 'prior', 'prize', 'proactive', 'probabl', 'problem', 'problems', 'probobl', 'procedur', 'procedurally', 'process', 'proclaim', 'prod', 'produc', 'product', 'products', 'profess', 'profound', 'programmers', 'progress', 'progression', 'project', 'projector', 'projects', 'prolong', 'promis', 'promot', 'prompt', 'prong', 'proof', 'prop', 'proper', 'properly', 'properti', 'propos', 'proposit', 'pros', 'prospect', 'prove', 'proven', 'provid', 'provide', 'ps', 'psst', 'psycholog', 'puff', 'pull', 'pummel', 'pump', 'pun', 'punchlin', 'punish', 'punishingly', 'punning', 'purchas', 'purchase', 'pure', 'purest', 'puriti', 'purpos', 'purpose', 'push', 'pusher', 'pushes', 'pushing', 'put', 'putter', 'puzl', 'puzzel', 'puzzl', 'puzzle', 'puzzler', 'puzzlers', 'puzzles', 'puzzlescript', 'puzzlesolving', 'puzzling', 'qix', 'qjacibf1rkg', 'qu', 'quadrant', 'qual', 'qualif', 'qualiti', 'quality', 'quantiti', 'quarter', 'question', 'quick', 'quid', 'quiet', 'quirki', 'quirky', 'quit', 'quite', 'race', 'rage', 'rais', 'ramif', 'ramp', 'ran', 'random', 'rang', 'rapid', 'rare', 'rate', 'rather', 'rating', 'ration', 'rave', 'raw', 're', 'reach', 'reaction', 'read', 'readabl', 'readi', 'ready', 'real', 'realis', 'realised', 'realistically', 'realiti', 'reality', 'realiz', 'realization', 'realize', 'realli', 'really', 'rearranged', 'reason', 'reasonable', 'reasons', 'rebuild', 'reccomend', 'reccommend', 'receiv', 'recent', 'recogn', 'recognit', 'recommand', 'recommend', 'recommendation', 'recommended', 'reconfigur', 'reconsid', 'record', 'recorder', 'recreat', 'recurs', 'red', 'redhead', 'redo', 'reek', 'reel', 'reflex', 'reflexes', 'refund', 'refunded', 'refus', 'regard', 'regions', 'regret', 'regular', 'reinvented', 'rel', 'relat', 'relationship', 'relax', 'releas', 'release', 'released', 'relentless', 'relev', 'reli', 'relic', 'relieve', 'remain', 'remark', 'remeb', 'rememb', 'remind', 'reminisc', 'remorse', 'remot', 'remote', 'render', 'repeat', 'repetit', 'repetition', 'repetitive', 'replac', 'replay', 'report', 'repres', 'repuls', 'repurchased', 'reput', 'requir', 'required', 'rereleas', 'reset', 'resign', 'resist', 'resolution', 'respect', 'response', 'rest', 'restart', 'restrict', 'result', 'resume', 'retain', 'retali', 'retread', 'retriev', 'return', 'reveal', 'revelation', 'rever', 'revers', 'review', 'reviewed', 'reviewer', 'reviews', 'reviv', 'revolutionari', 'revolv', 'reward', 'rewarded', 'rewarding', 'rewind', 'rewinding', 'rewir', 'rich', 'richness', 'rid', 'ridicul', 'ridiculous', 'right', 'rigid', 'rise', 'risk', 'roast', 'rock', 'rocks', 'rol', 'roll', 'rolled', 'roller', 'rollercoaster', 'rolling', 'rolls', 'room', 'root', 'rotat', 'rotate', 'rotating', 'rough', 'round', 'routin', 'rubik', 'rubric', 'rudimentary', 'ruin', 'ruins', 'rule', 'rules', 'ruleset', 'run', 'runner', 'running', 'rush', 'sack', 'sad', 'sadness', 'safe', 'sages', 'said', 'sake', 'sale', 'sales', 'salt', 'same', 'sampl', 'sand', 'sanity', 'sat', 'satisfact', 'satisfaction', 'satisfactori', 'satisfi', 'satisfying', 'sau', 'sauag', 'sauasag', 'sausag', 'sausage', 'sausagery', 'sausages', 'sav', 'save', 'savor', 'savvi', 'saw', 'say', 'says', 'scab', 'scaffold', 'scale', 'scam', 'scar', 'scarec', 'scatter', 'scenario', 'scenarios', 'scene', 'scheme', 'school', 'scope', 'scratch', 'screen', 'screens', 'screenshot', 'screw', 'script', 'scrubber', 'se', 'sea', 'seamless', 'search', 'seat', 'second', 'secondly', 'seconds', 'secret', 'secrets', 'section', 'sector', 'see', 'seed', 'seeing', 'seem', 'seemingly', 'seemless', 'seems', 'seen', 'seep', 'segment', 'segments', 'seha', 'seldem', 'select', 'sell', 'seller', 'selv', 'send', 'sens', 'sensat', 'sense', 'senses', 'sentenc', 'separ', 'sequel', 'sequenc', 'seren', 'seri', 'serialist', 'serious', 'seriously', 'serv', 'session', 'set', 'setup', 'sever', 'severely', 'sex', 'sh', 'shade', 'shader', 'shading', 'shadow', 'shall', 'shallow', 'shame', 'shape', 'share', 'sharp', 'sheer', 'shelf', 'shi', 'shines', 'ship', 'shipwreck', 'shit', 'shock', 'shore', 'short', 'shot', 'should', 'shoulder', 'shout', 'shovel', 'shoving', 'show', 'showcas', 'shown', 'shrine', 'shut', 'sicken', 'side', 'sides', 'sigh', 'sight', 'sign', 'signific', 'silence', 'silent', 'silli', 'silliest', 'silly', 'similar', 'similiar', 'simpl', 'simple', 'simpler', 'simplest', 'simpli', 'simplic', 'simplicity', 'simplist', 'simplistic', 'simply', 'simultan', 'sinc', 'since', 'sincer', 'singl', 'single', 'singular', 'sink', 'sip', 'siriusli', 'sit', 'site', 'sites', 'sitting', 'situat', 'situations', 'six', 'sixth', 'size', 'sizzl', 'skeptic', 'skewer', 'skewering', 'skill', 'skip', 'skyrim', 'slam', 'sleep', 'sleeve', 'slept', 'slide', 'sliders', 'slight', 'slightest', 'slim', 'slog', 'slot', 'slow', 'slowli', 'slowly', 'smack', 'small', 'smaller', 'smallest', 'smallish', 'smart', 'smarter', 'smartest', 'smash', 'smell', 'smile', 'smoke', 'smooth', 'snack', 'snake', 'snakebird', 'snappi', 'snappy', 'snatch', 'so', 'soak', 'societi', 'soft', 'soggi', 'soko', 'sokoban', 'sokobon', 'soldier', 'sole', 'solemnly', 'solid', 'solitari', 'solut', 'solution', 'solutions', 'solv', 'solve', 'solved', 'solver', 'solvers', 'solving', 'som', 'some', 'someday', 'somehow', 'someon', 'someth', 'something', 'sometihng', 'sometim', 'sometimes', 'somewhat', 'somewher', 'somewhere', 'somnanbulist', 'somth', 'sonny', 'soon', 'sooner', 'sooo', 'sooooo', 'sooth', 'soothing', 'sophist', 'sore', 'sorry', 'sort', 'sorts', 'sotn', 'soul', 'souls', 'sound', 'soundscap', 'soundtrack', 'sourc', 'source', 'space', 'spacebar', 'spacechem', 'spaces', 'spacial', 'span', 'spare', 'spars', 'spatial', 'speak', 'special', 'specif', 'specific', 'spectacle', 'spectacular', 'spectrum', 'spell', 'spend', 'spent', 'spicer', 'spicy', 'spider', 'spike', 'spin', 'spiritu', 'spoil', 'spoiler', 'spoilers', 'spoking', 'spong', 'sponge', 'sport', 'spot', 'spray', 'spur', 'squar', 'squares', 'squeez', 'ssr', 'stab', 'stack', 'stage', 'stagger', 'stand', 'standard', 'standards', 'standart', 'standing', 'starcraft', 'stardew', 'stare', 'starse', 'start', 'starter', 'starts', 'state', 'statement', 'statue', 'stay', 'staz', 'steadi', 'steadili', 'steam', 'steampowered', 'steep', 'stellar', 'step', 'stephen', 'steroids', 'steven', 'stick', 'sticki', 'stifl', 'still', 'stills', 'stimul', 'stock', 'stockholm', 'stone', 'stop', 'storag', 'store', 'stori', 'story', 'storytelling', 'straight', 'straightforward', 'strang', 'strange', 'stranger', 'strateg', 'strategi', 'strategic', 'straws', 'stream', 'strength', 'strenuous', 'stress', 'stretch', 'strike', 'string', 'strip', 'strive', 'stroke', 'strong', 'stronger', 'structur', 'structure', 'struggl', 'struggle', 'stuck', 'stuff', 'stumbl', 'stump', 'stumped', 'stun', 'stupid', 'stupidity', 'sturggl', 'stutter', 'styl', 'style', 'stylish', 'suasag', 'subconscious', 'subdu', 'subgenr', 'subgrenr', 'sublim', 'sublime', 'sublimin', 'subscribe', 'subsect', 'substanti', 'substantial', 'subtl', 'subtle', 'subtleti', 'subtly', 'succeed', 'success', 'successfully', 'succul', 'such', 'suck', 'sudden', 'suddenly', 'suffer', 'suffic', 'suggest', 'suggestion', 'suggestions', 'suitabl', 'summary', 'summer', 'super', 'superimpos', 'superlatives', 'suppli', 'support', 'suppos', 'suppose', 'suprem', 'supremaci', 'supress', 'supris', 'sure', 'surfac', 'surface', 'surpass', 'surpris', 'surprise', 'surprised', 'surprises', 'surprising', 'surpriz', 'surpufluo', 'surreal', 'surround', 'surroundings', 'suspect', 'swear', 'sweat', 'sweet', 'swing', 'switch', 'sword', 'syndrom', 'system', 'systematically', 'tabl', 'tackl', 'tactic', 'tad', 'tag', 'tail', 'tak', 'take', 'taken', 'tale', 'talent', 'talk', 'tall', 'talo', 'tank', 'tannhaus', 'target', 'tarkovski', 'task', 'tast', 'taste', 'tasti', 'taught', 'taunt', 'tea', 'teach', 'tear', 'tears', 'teas', 'teaser', 'teasers', 'technic', 'techniqu', 'techniques', 'tedious', 'tedium', 'tedius', 'teeth', 'tel', 'tell', 'temperatur', 'tempt', 'ten', 'tend', 'tenth', 'term', 'termin', 'terms', 'terrain', 'terribl', 'ters', 'terse', 'test', 'tester', 'testing', 'tetris', 'text', 'texts', 'textur', 'tfw', 'th', 'tha', 'thank', 'thankfully', 'that', 'the', 'thee', 'theer', 'their', 'them', 'theme', 'themselves', 'then', 'theorem', 'theori', 'theory', 'there', 'therebi', 'therefor', 'these', 'they', 'thick', 'thin', 'thing', 'thingi', 'things', 'think', 'thinking', 'third', 'thirti', 'this', 'tho', 'thorough', 'those', 'thou', 'though', 'thought', 'thoughtfully', 'thread', 'three', 'thrice', 'thrill', 'thrive', 'through', 'throughout', 'throw', 'thrown', 'thumb', 'thus', 'tidi', 'tight', 'tightest', 'til', 'tile', 'tiles', 'tileset', 'tilt', 'time', 'timelin', 'timer', 'times', 'tin', 'tini', 'tiny', 'tip', 'tire', 'titan', 'titl', 'title', 'titles', 'titular', 'to', 'today', 'toes', 'togeth', 'together', 'told', 'tombstone', 'ton', 'tone', 'too', 'took', 'tool', 'top', 'topic', 'topography', 'tops', 'torrent', 'tortur', 'toss', 'total', 'totallt', 'touch', 'tough', 'tout', 'toward', 'towards', 'tower', 'toy', 'traceback', 'track', 'tracks', 'tradeoff', 'tradit', 'trailer', 'train', 'tranquil', 'transcendent', 'transit', 'transpar', 'transparency', 'transport', 'trap', 'trapped', 'traumat', 'travers', 'treasur', 'treat', 'tremend', 'trepid', 'trhnhlv96jg', 'tri', 'trial', 'triangles', 'trick', 'tricki', 'trickier', 'tricks', 'tricksi', 'tricky', 'tries', 'trigger', 'tripl', 'triumph', 'troll', 'trouble', 'troublesom', 'true', 'trueli', 'truley', 'truli', 'trump', 'trust', 'truth', 'try', 'tube', 'tune', 'turn', 'turrets', 'turtl', 'tutori', 'tutorial', 'tutorials', 'tv', 'tw', 'twenti', 'twice', 'twist', 'twists', 'twitch', 'two', 'type', 'ugli', 'uglier', 'ugly', 'ui', 'ultim', 'ultimately', 'unabl', 'unapp', 'unapplic', 'unassum', 'unbeliev', 'unchang', 'uncompromising', 'unconsci', 'unconventional', 'uncooked', 'uncov', 'uncut', 'under', 'underestim', 'underground', 'underplay', 'understand', 'understandable', 'understanding', 'understatement', 'understood', 'undo', 'undos', 'undoubt', 'unedit', 'unequivoc', 'uneven', 'unexpect', 'unfair', 'unfold', 'unfortun', 'unfortunately', 'ungod', 'unintent', 'unintuative', 'unintuit', 'uniqu', 'unique', 'uniron', 'univers', 'unknown', 'unless', 'unlik', 'unlimit', 'unlock', 'unlocked', 'unnattract', 'unnecessari', 'unnecessarili', 'unnecessary', 'unparallel', 'unpolish', 'unravel', 'unrealist', 'unrel', 'unreserv', 'unrivaled', 'unsettl', 'unsettling', 'unsold', 'unsolvable', 'unspeak', 'unsur', 'untangl', 'untap', 'unti', 'until', 'untouch', 'unus', 'unusu', 'unveil', 'up', 'upcom', 'updat', 'upfront', 'upon', 'upward', 'urg', 'urgent', 'url', 'us', 'usd', 'use', 'useful', 'useless', 'user', 'usual', 'usually', 'util', 'utmost', 'utter', 'vagu', 'vague', 'valid', 'valley', 'valu', 'value', 'vari', 'variat', 'varieti', 'variety', 'various', 'vary', 'vast', 'vegan', 'vegetarians', 'vehicl', 'veil', 'vein', 'ventur', 'verb', 'verbal', 'verg', 'veri', 'versa', 'version', 'vertic', 'vertically', 'vertigin', 'very', 'vestig', 'veteran', 'via', 'vibrant', 'vice', 'victim', 'victory', 'video', 'videos', 'view', 'virtu', 'virtual', 'viscous', 'vision', 'visual', 'visuals', 'vocabulari', 'voic', 'void', 'vote', 'voxel', 'wad', 'wait', 'walk', 'walkthrough', 'walkthroughs', 'wall', 'walls', 'wander', 'wandering', 'wang', 'want', 'wanted', 'warehous', 'warm', 'warned', 'warning', 'warrant', 'was', 'wasd', 'wast', 'waste', 'watch', 'water', 'wave', 'way', 'ways', 'we', 'weak', 'weakest', 'wealth', 'weari', 'weary', 'weather', 'web', 'websit', 'website', 'wee', 'week', 'weekends', 'weeks', 'weiner', 'weird', 'weirdo', 'welcom', 'welcome', 'welcoming', 'well', 'welp', 'went', 'wet', 'what', 'whatev', 'whatnot', 'whatsoever', 'wheel', 'when', 'whenev', 'where', 'wheth', 'whether', 'whi', 'which', 'while', 'whilst', 'whim', 'whimsic', 'who', 'whoa', 'whole', 'wholeheart', 'wholli', 'whose', 'whut', 'why', 'wide', 'wider', 'wield', 'wieners', 'wild', 'will', 'win', 'wind', 'window', 'wins', 'wires', 'wiring', 'wisdom', 'wise', 'wish', 'wishlist', 'wit', 'with', 'wither', 'within', 'without', 'witness', 'woah', 'woke', 'woken', 'wonder', 'wonderful', 'wood', 'word', 'work', 'works', 'world', 'worlds', 'worri', 'worry', 'worth', 'woudn', 'would', 'wouldn', 'wound', 'woven', 'wow', 'wrack', 'wrap', 'wrench', 'wrest', 'wrestl', 'wring', 'wrinkl', 'write', 'writing', 'wrong', 'wrote', 'wrought', 'wsad', 'wtf', 'wurst', 'www', 'xjmtngpkzz0', 'ya', 'yeah', 'year', 'years', 'yell', 'yes', 'yesssss', 'yet', 'ymmv', 'you', 'your', 'yourself', 'youtu', 'youtub', 'zachtron', 'zen', 'zero', 'zone'] 3845\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(stemmed_reviews)\n",
    "print(vectorizer.get_feature_names(), len(vectorizer.get_feature_names()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "sortby not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-67e82e5f8a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: sortby not found"
     ]
    }
   ],
   "source": [
    "def tokenize(review):\n",
    "\n",
    "    ws_tokenized = ws_tokenizer.tokenize(review)\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token in ws_tokenized:\n",
    "        if token not in stopwords:\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    return cleaned_tokens\n",
    "\n",
    "def stem_tokens(cleaned_tokens, *args):\n",
    "\n",
    "    stemmed_tokens = []\n",
    "\n",
    "    try:\n",
    "        method = args[0]\n",
    "    except:\n",
    "        method = 'lancaster'\n",
    "\n",
    "    if method == 'lancaster':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(lancaster.stem(token))\n",
    "\n",
    "    elif method == 'porter':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(porter.stem(token))\n",
    "\n",
    "    elif method == 'snowball':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(snowball.stem(token))\n",
    "\n",
    "    return stemmed_tokens\n",
    "\n",
    "def full_review_stemmed(cleaned_tokens, *args):\n",
    "\n",
    "    stemmed_tokens = []\n",
    "\n",
    "    try:\n",
    "        method = args[0]\n",
    "    except:\n",
    "        method = 'lancaster'\n",
    "\n",
    "    if method == 'lancaster':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(lancaster.stem(token))\n",
    "\n",
    "    elif method == 'porter':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(porter.stem(token))\n",
    "\n",
    "    elif method == 'snowball':\n",
    "        for token in cleaned_tokens:\n",
    "            stemmed_tokens.append(snowball.stem(token))\n",
    "\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n",
    "\n",
    "    return stemmed_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
